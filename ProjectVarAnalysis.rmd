---
title: "ProjectVARAnalysis"
author: "Tommy Le"
date: "2025-04-05"
output:
  html_document: default
  pdf_document: default
---

{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.

When you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

{r pressure, echo=TRUE}
# Load all required packages for VAR analysis
library(zoo)
library(lubridate)
library(mgcv)
library(TSA)
library(dynlm)
library(tseries)  # This contains the adf.test function
library(car)
library(MuMIn)
library(ggplot2)
library(reshape2)
library(vars)
library(tsDyn)
library(forecast)
library(urca)

# Function to exclude a specific time window from a time series
exclude_window <- function(ts_data, start_exclude = c(2019, 1), end_exclude = c(2021, 4)) {
  time_idx <- time(ts_data)
  year_quarter <- as.yearqtr(time_idx)
  mask <- !(year_quarter >= as.yearqtr(start_exclude[1] + (start_exclude[2] - 1) / 4) &
              year_quarter <= as.yearqtr(end_exclude[1] + (end_exclude[2] - 1) / 4))
  return(ts_data[mask])
}

# Function to load and prepare data
load_and_prepare_data <- function() {
  # Load the rental vacancy data
  vacancy_df <- read.csv("Rental Vacancy Rate.csv")
  vacancy <- ts(vacancy_df$RRVRUSQ156N, start = c(1987, 1), frequency = 4)

  # Load or create housing price data
  if(file.exists("National Home Price Index.csv")) {
    housing_prices_df <- read.csv("National Home Price Index.csv", header = TRUE)
    housing_prices <- ts(housing_prices_df$CSUSHPINSA, start = c(1987, 1), frequency = 4)
  } else {
    set.seed(123)
    housing_prices <- ts(100 + cumsum(rnorm(length(vacancy), 0.5, 1)),
                           start = c(1987, 1), frequency = 4)
    cat("Note: Using synthetic housing price data\n")
  }

  # Load or create mortgage rate data
  if(file.exists("Fixed Rate Mortgage Average.csv")) {
    mortgage_rates_df <- read.csv("Fixed Rate Mortgage Average.csv", header = TRUE)
    mortgage_rates <- ts(mortgage_rates_df$MORTGAGE30US, start = c(1987, 1), frequency = 4)
  } else {
    set.seed(456)
    mortgage_rates <- ts(6 + cumsum(rnorm(length(vacancy), -0.02, 0.2)),
                           start = c(1987, 1), frequency = 4)
    cat("Note: Using synthetic mortgage rate data\n")
  }

  # Load or create disposable income data
  if(file.exists("Household Debt Service Payments as a Percent of Disposable Personal Income.csv")) {
    disposable_income_df <- read.csv("Household Debt Service Payments as a Percent of Disposable Personal Income.csv", header = TRUE)
    disposable_income <- ts(disposable_income_df$TDSP, start = c(1987, 1), frequency = 4)
  } else {
    set.seed(678)
    disposable_income <- ts(6 + cumsum(rnorm(length(vacancy), -0.02, 0.2)),
                           start = c(1987, 1), frequency = 4)
    cat("Note: Using synthetic disposable income data\n")
  }

  # Ensure all series have the same length by truncating to the shortest series
  min_length <- min(length(vacancy), length(housing_prices), length(mortgage_rates), length(disposable_income))
  vacancy <- window(vacancy, end = c(1987 + (min_length - 1) %/% 4, (min_length - 1) %% 4 + 1))
  housing_prices <- window(housing_prices, end = c(1987 + (min_length - 1) %/% 4, (min_length - 1) %% 4 + 1))
  mortgage_rates <- window(mortgage_rates, end = c(1987 + (min_length - 1) %/% 4, (min_length - 1) %% 4 + 1))
  disposable_income <- window(disposable_income, end = c(1987 + (min_length - 1) %/% 4, (min_length - 1) %% 4 + 1))

  # Exclude the specified time window
  #vacancy <- exclude_window(vacancy)
  #housing_prices <- exclude_window(housing_prices)
  #mortgage_rates <- exclude_window(mortgage_rates)
  #disposable_income <- exclude_window(disposable_income)

  # Combine data into a multivariate time series object
  combined_data <- cbind(Vacancy = vacancy,
                         Housing_Price = housing_prices,
                         Mortgage_Rate = mortgage_rates,
                         Disposable_Income = disposable_income)

  return(list(vacancy = vacancy,
              combined_data = combined_data))
}
# Function for VECM analysis
vecm_analysis <- function(data_list) {
  # Retrieve the multivariate time series data
  combined_data <- data_list$combined_data

  # Johansen cointegration test
  johansen_test <- ca.jo(combined_data, type = "trace", K = 5, ecdet = "const") 
  summary_test=summary(johansen_test)
  print(summary_test)
  test_stat <- summary_test@teststat
  critical_values <- summary_test@cval
  rank <- sum(test_stat > critical_values[, "1pct"])
  print (rank)
  

  if (rank > 0) {
    cat("\nCointegration detected. Proceeding with VECM.\n")
    # Estimate the VECM model
    vecm_model <- VECM(combined_data, lag = 2, r = rank, include = "const") 
    summary(vecm_model)
    return(vecm_model)
  } else {
    cat("\nNo cointegration detected. VECM is not appropriate.\n")
    return(NULL)
  }
}
var_analysis <- function(data_list) {
  # Retrieve the multivariate time series data
  combined_data <- data_list$combined_data

  # Test for stationarity in each series
  cat("\nStationarity Tests for Each Variable:\n")
  for (i in 1:ncol(combined_data)) {
    cat("\nADF Test for", colnames(combined_data)[i], ":\n")
    tryCatch({
      print(tseries::adf.test(combined_data[, i]))
    }, error = function(e) {
      cat("Error in ADF test:", e$message, "\n")
      cat("Proceeding with assumption that series is non-stationary\n")
    })
  }

  # First difference to achieve stationarity
  d_combined_data <- diff(combined_data)

  # Check stationarity after differencing
  cat("\nStationarity Tests After Differencing:\n")
  for (i in 1:ncol(d_combined_data)) {
    cat("\nADF Test for differenced", colnames(d_combined_data)[i], ":\n")
    tryCatch({
      print(tseries::adf.test(d_combined_data[, i]))
    }, error = function(e) {
      cat("Error in ADF test:", e$message, "\n")
      cat("Proceeding with assumption that differenced series is stationary\n")
    })
  }

  # Determine optimal lag order for VAR model
  lag_selection <- VARselect(d_combined_data, lag.max = 20)
  optimal_lag <- lag_selection$selection["AIC(n)"]
  cat("\nOptimal lag according to AIC:", optimal_lag, "\n")

  # Fit the VAR model
  var_model <- VAR(d_combined_data, p = optimal_lag)
  print(summary(var_model))

  # Granger causality tests
  cat("\nGranger Causality Tests:\n")
  for (i in 1:ncol(d_combined_data)) {
    cat("\nGranger causality for", colnames(d_combined_data)[i], ":\n")
    print(causality(var_model, cause = colnames(d_combined_data)[i]))
  }

  return(var_model)
}

create_interaction_terms <- function(disposable_income) {
  # Create income quintile based on disposable_income
  income_quintile <- cut(disposable_income, breaks = quantile(disposable_income, probs = 0:5/5), 
                         labels = FALSE, include.lowest = TRUE)
  
  # Create interaction term (disposable_income * income_quintile)
  interaction_term <- disposable_income * income_quintile
  
  return(data.frame(income_quintile = income_quintile, interaction_term = interaction_term))
}
load_and_prepare_data_with_interactions <- function() {
  data_list <- load_and_prepare_data()
 
  # Add interaction terms to the combined data
  interaction_terms <- create_interaction_terms(data_list$combined_data[, "Disposable_Income"])
 
  # Combine the interaction terms with the original data
  combined_data_with_interactions <- cbind(data_list$combined_data, interaction_terms)
  
  return(list(vacancy = data_list$vacancy, combined_data = combined_data_with_interactions))
}

# Modify VECM analysis to include exogenous variables with interaction terms
vecm_analysis_with_interactions <- function(data_list) {
  # Retrieve the multivariate time series data with interaction terms
  combined_data <- data_list$combined_data
  
  print(combined_data)
  # Johansen cointegration test
  johansen_test <- ca.jo(combined_data, type = "trace", K = 5, ecdet = "const") 
  summary_test = summary(johansen_test)
  print(summary_test)
  test_stat <- summary_test@teststat
  critical_values <- summary_test@cval
  rank <- sum(test_stat > critical_values[, "1pct"])
  print(rank)
  
  if (rank > 0) {
    cat("\nCointegration detected. Proceeding with VECM.\n")
    # Estimate the VECM model, including interaction term in exogenous variables
    vecm_model <- VECM(combined_data, lag = 2, r = rank, exog = combined_data[, c("interaction_terms.income_quintile", "interaction_terms.interaction_term")], include = "const") 
    summary(vecm_model)
    return(vecm_model)
  } else {
    cat("\nNo cointegration detected. VECM is not appropriate.\n")
    return(NULL)
  }
}



# Execute the VAR analysis
data_list <- tryCatch({
  load_and_prepare_data()
}, error = function(e) {
  cat("Error loading data:", e$message, "\n")
  return(NULL)
})

if (!is.null(data_list)) {
  var_model <- var_analysis(data_list)
   # Perform VECM analysis
  vecm_model <- vecm_analysis(data_list)
  print(vecm_model)
  
  # Only proceed with SVAR if VAR model was successfully created
  if (!is.null(var_model)) {
    # Structural VAR (SVAR) Analysis
    svar_analysis <- function(var_model, combined_data) {
      # Define Amat (contemporaneous relationships) and Bmat (structural shocks)
      A_mat <- matrix(0, 4, 4)
      A_mat[2, 1] <- NA  # Housing_Price can be affected by Vacancy
      A_mat[3, 1] <- NA  # Mortgage_Rate can be affected by Vacancy
      A_mat[3, 2] <- NA  # Mortgage_Rate can be affected by Housing_Price
      # A_mat[3, 3] <- NA # This would imply Mortgage_Rate is contemporaneously affected by itself, which is typically set to 0 or a fixed value of 1 for identification.

      # Define Bmat (diagonal with free parameters)
      B_mat <- diag(4)
      diag(B_mat) <- NA  # Keep diagonal elements free for identification

      # Ensure both A_mat and B_mat are defined properly
      if (all(is.na(A_mat)) || all(is.na(B_mat))) {
        stop("A_mat or B_mat is improperly defined.")
      }

      # Estimate the SVAR model
      tryCatch({
        cat("\nEstimating SVAR model...\n")
        svar_model <- SVAR(var_model, Amat = A_mat, Bmat = B_mat)
        if (is.null(svar_model)) {
          stop("svar_model is not fitted correctly.")
        }
        summary(svar_model)


        # Forecast Error Variance Decomposition
        svar_fevd <- fevd(svar_model, n.ahead = 8)
        if (is.null(svar_fevd)) {
          stop("svar_fevd is not fitted correctly.")
        }
        par(mar = c(2, 2, 2, 1))
        plot(svar_fevd)

        return(svar_model)
      }, error = function(e) {
        cat("Error in SVAR analysis:", e$message, "\n")
        return(NULL)
      })
    }

    # Execute SVAR analysis
    svar_model <- svar_analysis(var_model, data_list$combined_data)
    print(svar_model)
  }
  
  # tvar section:
   d_data <- na.omit(diff(data_list$combined_data))
  
  # Extract threshold variable as numeric vector (must match rows of d_data)
  th_var <- d_data[, "Disposable_Income"]
  
  # Sanity check
  cat("Data rows:", nrow(d_data), "| Threshold vector length:", length(th_var), "\n")
  
  d_data_ts <- ts(d_data)

  # Fit TVAR model
  tvar_model <- TVAR(d_data_ts,
                                   lag = 1,
                                   nthresh = 1,
                                   thVar = th_var,
                                   model = "TAR",
                                   commonInter = TRUE)

  print(tvar_model)
  plot(tvar_model)
  
}

data_list <- tryCatch({
  load_and_prepare_data_with_interactions()
}, error = function(e) {
  cat("Error loading data:", e$message, "\n")
  return(NULL)
})

# Perform the VECM analysis with interaction terms
if (!is.null(data_list)) {
  vecm_model <- vecm_analysis_with_interactions(data_list)
  print(vecm_model)
  
}

Summary Interpretation

All variables are I(1) and became stationary after differencing.

The VAR(1) model is stable and appropriately specified.

Own lags (Vacancy.l1, Housing_Price.l1, Mortgage_Rate.l1) are significant for some variables, suggesting persistence.

There is no Granger causality, but instantaneous causality exists, especially for housing prices and disposable income.

Covariance and correlation matrices show modest linear relationships among residuals, but nothing too strong.

Note that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot.
